{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb54a96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:48:49.512456Z",
     "start_time": "2021-07-15T12:48:46.946937Z"
    }
   },
   "source": [
    "# Federated Learning Implementation with tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b29fd2ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:57:57.329013Z",
     "start_time": "2021-07-15T23:57:57.321303Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Adult Dataset Salary Prediction \n",
    "# This is part of a study to investigate Differetinal privacy in Machine learning, Naturally we wish to compare it with federated learning.\n",
    "\n",
    "\n",
    "\n",
    "# Refrences:\n",
    "\n",
    "# [1] Federated Learning with Non-IID Data, Yue Zhao et al, arXiv: 1806.00582v1, 2 Jun 2018\n",
    "# [2] Communication-Efficient Learning of Deep Networks from Decentralized Data, H. Brendan McMahan et al, arXiv:1602.05629v3 [cs.LG] 28 Feb 2017\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "09b7dd46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:57:57.590963Z",
     "start_time": "2021-07-15T23:57:57.572204Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics import precision_score,recall_score, accuracy_score,confusion_matrix,f1_score\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "066207c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:51.783759Z",
     "start_time": "2021-07-15T23:59:51.727576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['client_1', 'client_2', 'client_3', 'client_4', 'client_5'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_clients(image_list, label_list, num_clients=10, initial='clients'):\n",
    "    \n",
    "    ''' return: a dictionary with keys clients' names and value as \n",
    "                data shards - tuple of images and label lists.\n",
    "        args: \n",
    "            image_list: a list of numpy arrays of training images\n",
    "            label_list:a list of binarized labels for each image\n",
    "            num_client: number of fedrated members (clients)\n",
    "            initials: the clients'name prefix, e.g, clients_1 \n",
    "            \n",
    "    '''\n",
    "\n",
    "    #create a list of client names\n",
    "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
    "\n",
    "    #randomize the data\n",
    "    data = list(zip(image_list, label_list))\n",
    "    random.shuffle(data)\n",
    "\n",
    "    #shard data and place at each client\n",
    "    size = len(data)//num_clients\n",
    "    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
    "\n",
    "    #number of clients must equal number of shards\n",
    "    assert(len(shards) == len(client_names))\n",
    "\n",
    "    return {client_names[i] : shards[i] for i in range(len(client_names))} \n",
    "\n",
    "\n",
    "clients = create_clients(X_train, y_train, num_clients=5, initial='client')\n",
    "print(clients.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "00b9bf6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:52.574848Z",
     "start_time": "2021-07-15T23:59:52.208912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9768, 94), (9768, 1))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train/Test Data seperation\n",
    "\n",
    "file_out = pd.read_csv('adult_processed.csv')\n",
    "cols = []\n",
    "for i in list(file_out.columns):\n",
    "    if  i != 'income':\n",
    "        cols.append(i)\n",
    "\n",
    "feature_set1 = pd.read_csv('train.csv')\n",
    "feature_set2 = pd.read_csv('test.csv')\n",
    "\n",
    "x = feature_set1[cols].copy().values\n",
    "y = feature_set1[['income']].copy().values\n",
    "        \n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(x)\n",
    "y_train = y\n",
    "\n",
    "x2 = feature_set2[cols].copy().values\n",
    "y2 = feature_set2[['income']].copy().values\n",
    "        \n",
    "X_test = sc.transform(x2)\n",
    "y_test = y2\n",
    "\n",
    "\n",
    "X_test.shape, y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "715ed657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:52.579114Z",
     "start_time": "2021-07-15T23:59:52.576244Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_data(data_shard, bs=64):\n",
    "    '''Takes in a clients data shard and create a tfds object off it\n",
    "    args:\n",
    "        shard: a data, label constituting a client's data shard\n",
    "        bs:batch size\n",
    "    return:\n",
    "        tfds object'''\n",
    "    #seperate shard into data and labels lists\n",
    "    data, label = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "    \n",
    "    return dataset.shuffle(len(label)).batch(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dfd80728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:54.563066Z",
     "start_time": "2021-07-15T23:59:52.773340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 94), (None, 1)), types: (tf.float64, tf.int64)>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#process and batch the training data for each client\n",
    "clients_batched = dict()\n",
    "for (client_name, data) in clients.items():\n",
    "    clients_batched[client_name] = batch_data(data)\n",
    "    \n",
    "#process and batch the test set  \n",
    "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))\n",
    "test_batched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9dcf2ff7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T23:59:54.568193Z",
     "start_time": "2021-07-15T23:59:54.564443Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleMLP:\n",
    "    @staticmethod\n",
    "    def build(shape, classes=2 , learning_rate = 0.001, metric = \"accuracy\"):\n",
    "\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128, input_shape = (shape,)))\n",
    "#         model.add(Dense(128, Activation(\"relu\")))\n",
    "#         model.add(Dense(64, Activation(\"relu\")))\n",
    "#         model.add(Dense(32, Activation(\"relu\")))\n",
    "#         model.add(Dense(1))\n",
    "        \n",
    "        model.add(Dense(128, Activation(\"tanh\")))\n",
    "        model.add(Dense(64, Activation(\"tanh\")))\n",
    "        model.add(Dense(32, Activation(\"tanh\")))\n",
    "        model.add(Dense(1,Activation('sigmoid')))\n",
    "        \n",
    "\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f71dc14a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:00:30.156165Z",
     "start_time": "2021-07-16T00:00:30.152576Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.005\n",
    "comms_round = 30\n",
    "loss=tf.keras.losses.BinaryCrossentropy(from_logits = False)\n",
    "\n",
    "metrics = ['binary_accuracy']\n",
    "\n",
    "optimizer = SGD(learning_rate=lr, \n",
    "                decay=lr / comms_round, \n",
    "                momentum=0.5\n",
    "               )     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eebf9376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:00:30.412962Z",
     "start_time": "2021-07-16T00:00:30.399142Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def weight_scalling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    #get the bs\n",
    "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    #first calculate the total training data points across clinets\n",
    "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
    "    # get the total number of data points held by a client\n",
    "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    return local_count/global_count\n",
    "\n",
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "#     print(len(scaled_weight_list))\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "#         print(len(grad_list_tuple))\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad\n",
    "\n",
    "\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    \n",
    "#     cce = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "#     cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    logits = model.predict(X_test)\n",
    "\n",
    "    score = global_model.evaluate(X_test, y_test, verbose=0)\n",
    "    acc = score[1] ; loss = score[0]\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
    "\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4aef41d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:01:47.756094Z",
     "start_time": "2021-07-16T00:00:30.586083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 0s 951us/step - loss: 0.5051 - binary_accuracy: 0.7539\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.5023 - binary_accuracy: 0.7586\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.5051 - binary_accuracy: 0.7577\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.5101 - binary_accuracy: 0.7494\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.5052 - binary_accuracy: 0.7572\n",
      "comm_round: 0 | global_acc: 82.617% | global_loss: 0.40433794260025024\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.3820 - binary_accuracy: 0.8325\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.3851 - binary_accuracy: 0.8288\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.3894 - binary_accuracy: 0.8266\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.3888 - binary_accuracy: 0.8253\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.3905 - binary_accuracy: 0.8213\n",
      "comm_round: 1 | global_acc: 83.845% | global_loss: 0.36178216338157654\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.3604 - binary_accuracy: 0.8331\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.3639 - binary_accuracy: 0.8371\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.3651 - binary_accuracy: 0.8298\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.3568 - binary_accuracy: 0.8404\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.3636 - binary_accuracy: 0.8379\n",
      "comm_round: 2 | global_acc: 84.244% | global_loss: 0.3466297388076782\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.3543 - binary_accuracy: 0.8343\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.3458 - binary_accuracy: 0.8439\n",
      "123/123 [==============================] - 1s 985us/step - loss: 0.3502 - binary_accuracy: 0.8349\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.3527 - binary_accuracy: 0.8400\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.3538 - binary_accuracy: 0.8403\n",
      "comm_round: 3 | global_acc: 84.521% | global_loss: 0.3388580083847046\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.3481 - binary_accuracy: 0.8427\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.3444 - binary_accuracy: 0.8377\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.3467 - binary_accuracy: 0.8431\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.3396 - binary_accuracy: 0.8444\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.3484 - binary_accuracy: 0.8361\n",
      "comm_round: 4 | global_acc: 84.562% | global_loss: 0.33413130044937134\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.3408 - binary_accuracy: 0.8411\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.3357 - binary_accuracy: 0.8466\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3428 - binary_accuracy: 0.8464\n",
      "123/123 [==============================] - 1s 997us/step - loss: 0.3444 - binary_accuracy: 0.8440\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.3443 - binary_accuracy: 0.8390\n",
      "comm_round: 5 | global_acc: 84.736% | global_loss: 0.33097970485687256\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3414 - binary_accuracy: 0.8391\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3418 - binary_accuracy: 0.8445\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3380 - binary_accuracy: 0.8422\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3327 - binary_accuracy: 0.8481\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.3400 - binary_accuracy: 0.8463\n",
      "comm_round: 6 | global_acc: 84.736% | global_loss: 0.32867559790611267\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.3380 - binary_accuracy: 0.8485\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.3398 - binary_accuracy: 0.8463\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.3359 - binary_accuracy: 0.8444\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.3305 - binary_accuracy: 0.8498\n",
      "123/123 [==============================] - 1s 966us/step - loss: 0.3393 - binary_accuracy: 0.8394\n",
      "comm_round: 7 | global_acc: 84.859% | global_loss: 0.3269461691379547\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3343 - binary_accuracy: 0.8444\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.3376 - binary_accuracy: 0.8413\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.3287 - binary_accuracy: 0.8504\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.3360 - binary_accuracy: 0.8483\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.3381 - binary_accuracy: 0.8466\n",
      "comm_round: 8 | global_acc: 84.951% | global_loss: 0.32552623748779297\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.3331 - binary_accuracy: 0.8453\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.3348 - binary_accuracy: 0.8504\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.3368 - binary_accuracy: 0.8472\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.3275 - binary_accuracy: 0.8509\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.3362 - binary_accuracy: 0.8409\n",
      "comm_round: 9 | global_acc: 85.002% | global_loss: 0.3243926167488098\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.3352 - binary_accuracy: 0.8412\n",
      "123/123 [==============================] - 1s 978us/step - loss: 0.3261 - binary_accuracy: 0.8490\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.3336 - binary_accuracy: 0.8483\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.3356 - binary_accuracy: 0.8480\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.3317 - binary_accuracy: 0.8454\n",
      "comm_round: 10 | global_acc: 84.930% | global_loss: 0.32341766357421875\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.3341 - binary_accuracy: 0.8409\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.3328 - binary_accuracy: 0.8492\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3346 - binary_accuracy: 0.8473\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.3253 - binary_accuracy: 0.8513\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.3308 - binary_accuracy: 0.8463\n",
      "comm_round: 11 | global_acc: 84.992% | global_loss: 0.3226086497306824\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.3319 - binary_accuracy: 0.8505\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.3301 - binary_accuracy: 0.8464\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.3332 - binary_accuracy: 0.8423\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.3243 - binary_accuracy: 0.8519\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.3337 - binary_accuracy: 0.8490\n",
      "comm_round: 12 | global_acc: 85.063% | global_loss: 0.3220551013946533\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.3331 - binary_accuracy: 0.8485\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.3293 - binary_accuracy: 0.8464\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.3325 - binary_accuracy: 0.8437\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.3309 - binary_accuracy: 0.8510\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.3237 - binary_accuracy: 0.8519\n",
      "comm_round: 13 | global_acc: 85.084% | global_loss: 0.32134726643562317\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.3230 - binary_accuracy: 0.8521\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.3305 - binary_accuracy: 0.8523\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.3324 - binary_accuracy: 0.8494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 954us/step - loss: 0.3318 - binary_accuracy: 0.8443\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.3286 - binary_accuracy: 0.8463\n",
      "comm_round: 14 | global_acc: 85.084% | global_loss: 0.3208298981189728\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.3319 - binary_accuracy: 0.8501\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.3312 - binary_accuracy: 0.8451\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.3223 - binary_accuracy: 0.8527\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.3297 - binary_accuracy: 0.8521\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.3280 - binary_accuracy: 0.8463\n",
      "comm_round: 15 | global_acc: 85.135% | global_loss: 0.32036617398262024\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.3275 - binary_accuracy: 0.8483\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.3293 - binary_accuracy: 0.8519\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.3218 - binary_accuracy: 0.8541\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.3306 - binary_accuracy: 0.8450\n",
      "123/123 [==============================] - 1s 948us/step - loss: 0.3314 - binary_accuracy: 0.8503\n",
      "comm_round: 16 | global_acc: 85.094% | global_loss: 0.3198656737804413\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.3214 - binary_accuracy: 0.8537\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.3269 - binary_accuracy: 0.8478\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.3301 - binary_accuracy: 0.8449\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.3288 - binary_accuracy: 0.8530\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.3308 - binary_accuracy: 0.8494\n",
      "comm_round: 17 | global_acc: 85.084% | global_loss: 0.3194718658924103\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.3304 - binary_accuracy: 0.8503\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3298 - binary_accuracy: 0.8459\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.3209 - binary_accuracy: 0.8536\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.3282 - binary_accuracy: 0.8527\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.3264 - binary_accuracy: 0.8483\n",
      "comm_round: 18 | global_acc: 85.104% | global_loss: 0.3190879225730896\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.3259 - binary_accuracy: 0.8489\n",
      "123/123 [==============================] - 1s 952us/step - loss: 0.3300 - binary_accuracy: 0.8512\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.3205 - binary_accuracy: 0.8542\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.3279 - binary_accuracy: 0.8531\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.3293 - binary_accuracy: 0.8446\n",
      "comm_round: 19 | global_acc: 85.125% | global_loss: 0.31878113746643066\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.3273 - binary_accuracy: 0.8532\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.3202 - binary_accuracy: 0.8524\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.3297 - binary_accuracy: 0.8499\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.3289 - binary_accuracy: 0.8445\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.3255 - binary_accuracy: 0.8494\n",
      "comm_round: 20 | global_acc: 85.217% | global_loss: 0.3185296356678009\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.3286 - binary_accuracy: 0.8454\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.3270 - binary_accuracy: 0.8526\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.3294 - binary_accuracy: 0.8510\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.3199 - binary_accuracy: 0.8545\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.3252 - binary_accuracy: 0.8483\n",
      "comm_round: 21 | global_acc: 85.125% | global_loss: 0.31818488240242004\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.3267 - binary_accuracy: 0.8535\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.3248 - binary_accuracy: 0.8495\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.3289 - binary_accuracy: 0.8518\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.3195 - binary_accuracy: 0.8535\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.3282 - binary_accuracy: 0.8460\n",
      "comm_round: 22 | global_acc: 85.186% | global_loss: 0.31791040301322937\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.3288 - binary_accuracy: 0.8519\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.3278 - binary_accuracy: 0.8462\n",
      "123/123 [==============================] - 1s 971us/step - loss: 0.3245 - binary_accuracy: 0.8496\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.3264 - binary_accuracy: 0.8531\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.3192 - binary_accuracy: 0.8536\n",
      "comm_round: 23 | global_acc: 85.197% | global_loss: 0.317658394575119\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.3261 - binary_accuracy: 0.8539\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.3276 - binary_accuracy: 0.8463\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.3189 - binary_accuracy: 0.8539\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.3242 - binary_accuracy: 0.8496\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.3285 - binary_accuracy: 0.8528\n",
      "comm_round: 24 | global_acc: 85.207% | global_loss: 0.317483127117157\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.3186 - binary_accuracy: 0.8541\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.3257 - binary_accuracy: 0.8539\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.3239 - binary_accuracy: 0.8510\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.3272 - binary_accuracy: 0.8464\n",
      "123/123 [==============================] - 1s 983us/step - loss: 0.3282 - binary_accuracy: 0.8509\n",
      "comm_round: 25 | global_acc: 85.268% | global_loss: 0.3172972798347473\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.3255 - binary_accuracy: 0.8530\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.3271 - binary_accuracy: 0.8458\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.3236 - binary_accuracy: 0.8498\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.3185 - binary_accuracy: 0.8544\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.3279 - binary_accuracy: 0.8515\n",
      "comm_round: 26 | global_acc: 85.166% | global_loss: 0.3170732855796814\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.3277 - binary_accuracy: 0.8513\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.3268 - binary_accuracy: 0.8460\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.3234 - binary_accuracy: 0.8500\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.3251 - binary_accuracy: 0.8531\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.3182 - binary_accuracy: 0.8539\n",
      "comm_round: 27 | global_acc: 85.268% | global_loss: 0.31693580746650696\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.3249 - binary_accuracy: 0.8530\n",
      "123/123 [==============================] - 1s 960us/step - loss: 0.3266 - binary_accuracy: 0.8462\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.3231 - binary_accuracy: 0.8507\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.3180 - binary_accuracy: 0.8546\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.3275 - binary_accuracy: 0.8519\n",
      "comm_round: 28 | global_acc: 85.238% | global_loss: 0.3167679011821747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 0s 940us/step - loss: 0.3273 - binary_accuracy: 0.8519\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.3264 - binary_accuracy: 0.8458\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.3248 - binary_accuracy: 0.8535\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.3229 - binary_accuracy: 0.8504\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.3176 - binary_accuracy: 0.8540\n",
      "comm_round: 29 | global_acc: 85.217% | global_loss: 0.31654173135757446\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#initialize global model\n",
    "smlp_global = SimpleMLP()\n",
    "global_model = smlp_global.build(X_train.shape[1] ,classes=2)\n",
    "global_model.compile(optimizer=optimizer, loss=loss, metrics=metrics) \n",
    "\n",
    "        \n",
    "#commence global training loop\n",
    "for comm_round in range(comms_round):\n",
    "            \n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    client_names= list(clients_batched.keys())\n",
    "    random.shuffle(client_names)\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in client_names:\n",
    "        smlp_local = SimpleMLP()\n",
    "        local_model = smlp_local.build(X_train.shape[1],classes=2)\n",
    "        local_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #fit local model with client's data\n",
    "        local_model.fit(clients_batched[client], epochs=1, verbose=1)\n",
    "        \n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "\n",
    "#     test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "670d1d42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:08.033027Z",
     "start_time": "2021-07-16T00:03:07.867893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31654173135757446, 0.8521703481674194]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = global_model.evaluate(X_test, y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1fcaa73e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:08.653744Z",
     "start_time": "2021-07-16T00:03:08.484057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.7267472411981083\n",
      "Recall = 0.599479843953186\n",
      "Accuracy = 0.8521703521703522\n",
      "f1 = 0.6570071258907364\n"
     ]
    }
   ],
   "source": [
    "nn_preds = global_model.predict(X_test)\n",
    "nn_preds = (nn_preds > 0.5)\n",
    "\n",
    "nn_precision =precision_score(y_test, nn_preds)\n",
    "nn_recall = recall_score(y_test, nn_preds)\n",
    "nn_accuracy = accuracy_score(y_test, nn_preds)\n",
    "nn_f1 = f1_score(y_test, nn_preds)\n",
    "\n",
    "\n",
    "print(\"Precision = {}\".format(nn_precision))\n",
    "print(\"Recall = {}\".format(nn_recall))\n",
    "print(\"Accuracy = {}\".format(nn_accuracy))\n",
    "print(\"f1 = {}\".format(nn_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6360dd5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T00:03:09.275052Z",
     "start_time": "2021-07-16T00:03:09.268152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 7865],\n",
       "       [   1, 1903]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = nn_preds > 0.5\n",
    "\n",
    "unique, counts = np.unique(arr, return_counts=True)\n",
    "\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a5ee99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T19:56:25.650336Z",
     "start_time": "2021-07-14T19:56:25.620Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a27b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
